# -*- coding: utf-8 -*-
"""Importance Sampling Simulation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wZdpJRisBaAY-jCk6ozYBK6RdxTxnKwg
"""

import numpy as np
from scipy.stats import beta
import matplotlib.pyplot as plt

# Generate beta distribution. Returns x and y values as a tuple
def create_beta_distribution(alpha_val, beta_val, num_data_points=1000):
  # Generate values for the x-axis
    x = np.linspace(0, 1, num_data_points)
  # Calculate the probability density function (PDF) for the beta distributions
    pdf = beta.pdf(x, alpha_val, beta_val)
    pdf = pdf / np.sum(pdf)
    return (x, pdf)

# Sample outcome using Representative Sampling. Returns index and value
def RS_sample_outcome(px, fx):
    outcome_indices = np.arange(len(fx))
    sampled_outcome_index = np.random.choice(outcome_indices, p=px)
    sampled_outcome_value = fx[sampled_outcome_index]
    return (sampled_outcome_index, sampled_outcome_value)

# Sample outcome using Importance Sampling. Returns index and value
def IS_sample_outcome(px, fx, qx):
    outcome_indices = np.arange(len(fx))
    # print("calculated qx")
    sampled_outcome_index = np.random.choice(outcome_indices, p=qx)
    sampled_outcome_value = fx[sampled_outcome_index]
    weight = px[sampled_outcome_index] / qx[sampled_outcome_index]
    return (sampled_outcome_index, sampled_outcome_value, weight)

def generate_qx_helper(px, fx):
    outcome_indices = np.arange(len(fx))
    qx = px*np.abs(fx)
    qx = qx / np.sum(qx)
    return qx

# Generate the q distribution
def generate_qx(px, fx):
    RS_samps = []
    px = px/np.sum(px)
    for i in range(10):
      _, sampled_outcome_value = RS_sample_outcome(px, fx)
      RS_samps.append(sampled_outcome_value)
    ex = np.mean(RS_samps)
    qx = px*np.abs((fx-ex))
    qx = qx / np.sum(qx)
    return qx

# Get estimated utility using Representative Sampling with 'num_samples' samples
def RS_get_estimated_utility(px, fx, num_samples=5):
    sampled_utilities = []
    sampled_indices = []
    for i in range(num_samples):
        sampled_index, sampled_utility= RS_sample_outcome(px, fx)
        sampled_utilities.append(sampled_utility)
    return np.mean(sampled_utilities)

# Get estimated utility using Importance Sampling with 'num_samples' samples
def IS_get_estimated_utility(px, fx, qx, num_samples=5):
    sampled_indices= []
    sampled_utilities = []
    sampled_weights = []
    for i in range(num_samples):
        sampled_index, sampled_utility, sampled_weight = IS_sample_outcome(px, fx, qx)
        sampled_indices.append(sampled_index)
        sampled_utilities.append(sampled_utility)
        sampled_weights.append(sampled_weight)
    # estimated_utility = (1 / np.sum(1 / np.array(sampled_utilities))) * len(sampled_utilities)
    estimated_utility = (1 / np.sum(sampled_weights)) * np.sum(np.array(sampled_utilities) * np.array(sampled_weights))
    return estimated_utility

# def IS_get_estimated_utils(px, fx, num_samples=5):

# # # Run 'num_simulations' simulations and take the average estimated utility for Representative Sampling
def multiple_RS_get_estimated_utility(px, fx, num_samples=5, num_simulations=1000):
    est_utils = []
    for i in range(num_simulations):
        est_utils.append(RS_get_estimated_utility(px, fx, num_samples))
    return est_utils

# Run 'num_simulations' simulations and take the average estimated utility for Importance Sampling
def multiple_IS_get_estimated_utility(px, fx, num_samples=5, num_simulations=1000):
    qx = generate_qx(px, fx)
    est_utils = []
    for i in range(num_simulations):
        est_utils.append(IS_get_estimated_utility(px, fx, qx, num_samples))
    return est_utils

# Function to create two side-by-side figures
def create_two_figures(x1_data, y1_data, title1="", xlabel1="", ylabel1="", color1="",
                   x2_data=None, y2_data=None, title2="", xlabel2="", ylabel2="", color2=""):
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))  # Adjust the figure size as needed

    # Plot data on the first subplot
    ax1.plot(x1_data, y1_data, color=color1)
    ax1.set_title(title1)
    ax1.set_xlabel(xlabel1)
    ax1.set_ylabel(ylabel1)
    ax1.grid(True)

    # Plot data on the second subplot
    ax2.plot(x2_data, y2_data, color=color2)
    ax2.set_title(title2)
    ax2.set_xlabel(xlabel2)
    ax2.set_ylabel(ylabel2)
    ax2.grid(True)

    # Adjust layout
    plt.tight_layout()

    # Show plot
    plt.show()

# Function to create one figure
def create_one_figure(x_data, y_data, title="", xlabel="", ylabel="", color=""):
    fig, ax = plt.subplots(figsize=(8, 6))  # Adjust the figure size as needed

    # Plot data on the single axis
    ax.plot(x_data, y_data, color=color)
    ax.set_title(title)
    ax.set_xlabel(xlabel)
    ax.set_ylabel(ylabel)
    ax.grid(True)

    # Show plot
    plt.show()

def generate_histogram(data, title="", xlabel="", ylabel=""):
  plt.hist(data, bins=20, color='skyblue', edgecolor='black', alpha=0.7, range=(np.min(data), np.max(data)))
  plt.xlabel(xlabel)
  plt.ylabel(ylabel)
  plt.title(title)
  # Calculate mean
  mean_value = 0
    # Add marker for mean
  plt.axvline(mean_value, color='red', linestyle='dashed', linewidth=1)
    # Add legend
  plt.legend(['Mean'])
  plt.grid(True)
  plt.show()

# Plotting p(x), f(x), and q(x) for Storming Capitol
import numpy as np
from scipy.stats import beta
import matplotlib.pyplot as plt

# axis_fontsize=18
nsamp = 100000

# # Storming the Capitol p(x)
p_beta_params = [1, 5]
x = np.linspace(.000001, .99999, nsamp)
# Calculate the probability density function (PDF) for the beta distributions
pdf = beta.pdf(x, p_beta_params[0], p_beta_params[1])

# plt.figure(figsize=(10, 6))  # Set figure size
# plt.plot(x, pdf, color='red', label='p(x)', linewidth=2)
# # plt.title("Probability Distribution of Percentage of Republicans\nBelieving They Should Storm the Capitol", fontsize=18)
# plt.xlabel("Percentage of Republicans Who Believe\nThey Should Storm the Capitol", fontsize=axis_fontsize)
# plt.ylabel("Probabibility Density", fontsize=axis_fontsize)
# plt.grid(True, linestyle='--', alpha=0.5)  # Add grid lines
# plt.legend(fontsize=12)
# plt.tight_layout()  # Adjust layout to prevent clipping
# plt.show()



# Storming the Capitol f(x)
m = -110
b = 10
x = np.linspace(0, 1, nsamp)  # Generate 100000 points from 0 to 1
y = m * x + b
# plt.figure(figsize=(10, 6))  # Set figure size
# plt.plot(x, y, color='blue', label='Utility Function: $y = -110x + 10$', linewidth=2)
# # plt.title("Utility Function for Republicans Believing They Should Storm the Capitol", fontsize=18)
# plt.xlabel("Percentage of Republicans Who Believe They Should Storm the Capitol", fontsize=axis_fontsize)
# plt.ylabel("Utility (Negative or Positive Impact)", fontsize=axis_fontsize)
# plt.yticks(np.arange(-100, 11, 10))
# plt.axhline(0, color='red', linestyle='--', label='Zero Utility', linewidth=1.5)
# plt.grid(True, linestyle='--', alpha=0.5)  # Add grid lines
# plt.legend(fontsize=12)
# plt.tight_layout()  # Adjust layout to prevent clipping
# plt.show()

# # Storming the Capitol q(x)
# qx = pdf * np.abs(y)

# plt.figure(figsize=(10, 6))  # Set figure size
# plt.plot(x, qx, color='orange', label='q(x)', linewidth=2)
# # plt.title("Distribution of q(x) for Republicans Storming the Capitol", fontsize=18)
# plt.xlabel("Percentage of Republicans Who Believe They Should Storm the Capitol", fontsize=axis_fontsize)
# plt.ylabel("Importance-Weighted Probability Density", fontsize=axis_fontsize)
# plt.grid(True, linestyle='--', alpha=0.5)  # Add grid lines
# plt.axhline(0, color='black', linewidth=0.5)  # Horizontal line at y=0
# plt.axvline(0, color='black', linewidth=0.5)  # Vertical line at x=0
# plt.legend(fontsize=12)
# plt.tight_layout()  # Adjust layout to prevent clipping
# plt.show()


# Storming the Capitol Representative Sampling Sampled Values Histogram
nsamp = 100000
m = -110
b = 10
x = np.linspace(0, 1, nsamp)
y = m * x + b
p_beta_params = [1, 5]
sampled_X = np.random.beta(p_beta_params[0], p_beta_params[1], nsamp)
scaled_indices = (sampled_X * (nsamp - 1)).astype(int)
prob_X = beta.pdf(sampled_X, p_beta_params[0], p_beta_params[1])
util_X = y[scaled_indices]
# plt.figure(figsize=(10, 6))
# plt.hist(util_X, bins=20, color='skyblue', edgecolor='black', alpha=0.7)
# plt.title("Histogram of Sampled Utility Values With Representative Sampling", fontsize=14)
# true_expected_utility = np.mean(y * pdf)
# standard_deviation = np.std(pdf*y)
# plt.axvline(np.mean(y*pdf), color='red', linestyle='--', label='True Expected Utility', linewidth=1.5)
# plt.axvline(true_expected_utility - 2 * standard_deviation, color='red', linestyle='--', label='-2 SD', linewidth=1.5, alpha=0.5)
# plt.axvline(true_expected_utility + 2 * standard_deviation, color='red', linestyle='--', label='+2 SD', linewidth=1.5, alpha=0.5)
# plt.xlabel("Utility Value", fontsize=12)
# plt.ylabel("Frequency", fontsize=12)
# plt.grid(True, linestyle='--', alpha=0.5)
# plt.show()

# Storming the Capitol Representative Sampling Estimated Utilities Histogram
all_RS_ests = []
for i in range(10000):
  samples = 5
  sampled_X = np.random.beta(p_beta_params[0], p_beta_params[1], samples)
  scaled_indices = (sampled_X * (nsamp - 1)).astype(int)
  prob_X = beta.pdf(sampled_X, p_beta_params[0], p_beta_params[1])
  util_X = y[scaled_indices]
  RS_est = np.mean(util_X)
  all_RS_ests.append(RS_est)

bin_start = -50
bin_end = 10
num_bins = 6

# Calculate the bin width
bin_width = (bin_end - bin_start) / num_bins

# Create bin edges
bin_edges = np.linspace(bin_start, bin_end, num=num_bins + 1)

RS_ests_arr = np.array(all_RS_ests)
num_above_0 = np.sum(RS_ests_arr > 0)

plt.figure(figsize=(10, 6))
plt.hist(all_RS_ests, bins=bin_edges, color='skyblue', edgecolor='black', alpha=0.7)
# plt.title("Histogram of Representative Sampling Estimates", fontsize=14)
true_expected_utility = np.mean(y * pdf)
plt.axhline(num_above_0, color='purple', linestyle='--', label="Number of Estimates Above 0")
standard_deviation = np.std(pdf*y)
plt.axvline(np.mean(y*pdf), color='red', linestyle='--', label='True Expected Utility', linewidth=1.5)
# plt.axvline(true_expected_utility - 2 * standard_deviation, color='red', linestyle='--', label='-2 SD', linewidth=1.5, alpha=0.5)
# plt.axvline(true_expected_utility + 2 * standard_deviation, color='red', linestyle='--', label='+2 SD', linewidth=1.5, alpha=0.5)
plt.axvline(0, color='green', label='Zero Utility')
plt.xlabel("Estimated Expected Utility Value", fontsize=22)
plt.ylabel("Frequency", fontsize=22)
ticks = np.arange(0, 5500, 500)
np.append(ticks, num_above_0)
plt.yticks(ticks)  # Add xtick at x=38
plt.legend(fontsize=18)
plt.grid(True, linestyle='--', alpha=0.5)
plt.show()


# Storming the Capitol Importance Sampling Sampled Values Histogram
IS_estimates = multiple_IS_get_estimated_utility(pdf, y, num_simulations=5)
ex = np.mean(IS_estimates)

qx = pdf * np.abs(y - ex)
qx = qx / np.sum(qx)
# Perform importance sampling estimation
all_IS_ests = []
# Sample `samples` points from `qx`
nsamp=100000
# sampled_utilities = []
# for i in range(nsamp):
#   sampled_index, sampled_utility, weight = IS_sample_outcome(pdf, y)
#   sampled_utilities.append(sampled_utility)

outcome_indices = np.arange(len(y))
# qx = generate_qx(pdf, y)
sampled_outcome_indices = np.random.choice(outcome_indices, p=qx, size=nsamp)
sampled_outcome_values = y[sampled_outcome_indices]
weight = y[sampled_outcome_indices] / qx[sampled_outcome_indices]

# scaled_indices = np.floor((sampled_X - np.min(qx)) / (np.max(qx) - np.min(qx)) * nsamp).astype(int) % nsamp
# util_X = y[scaled_indices]
# IS_est = np.mean(util_X)
# all_IS_ests.append(IS_est)
# plt.figure(figsize=(10, 6))
# plt.hist(sampled_outcome_values, bins=20, color='skyblue', edgecolor='black', alpha=0.7)
# plt.title("Histogram of Sampled Utility Values With Importance Sampling", fontsize=20)
# plt.xlabel("Estimated Expected Utility Value", fontsize=16)
# plt.ylabel("Frequency", fontsize=16)
# true_expected_utility = np.mean(y * pdf)
# standard_deviation = np.std(pdf*y)
# plt.axvline(np.mean(y*pdf), color='red', linestyle='--', label='True Expected Utility', linewidth=1.5)
# plt.axvline(0, color='green', label='Zero Utility')
# plt.axvline(true_expected_utility - 2 * standard_deviation, color='red', linestyle='--', label='-2 SD', linewidth=1.5, alpha=0.5)
# plt.axvline(true_expected_utility + 2 * standard_deviation, color='red', linestyle='--', label='+2 SD', linewidth=1.5, alpha=0.5)
# plt.grid(True, linestyle='--', alpha=0.5)
# plt.legend(fontsize=12)
# plt.show()

# Storming the Capitol Importance Sampling Estimated Utilities Histogram
nsamp = 100000
m = -110
b = 10
x = np.linspace(0, 1, nsamp)
y = m * x + b
p_beta_params = [1, 5]
sampled_X = np.random.choice(qx, samples)

scaled_indices = np.floor((sampled_X - np.min(qx)) / (np.max(qx) - np.min(qx)) * nsamp).astype(int) % nsamp

util_X = y[scaled_indices]
IS_ests = multiple_IS_get_estimated_utility(pdf, y, num_simulations=10000)
IS_ests_arr = np.array(IS_ests)
num_above_0 = np.sum(IS_ests_arr > 0)

plt.figure(figsize=(10, 6))
plt.hist(IS_ests, bins=bin_edges, color='skyblue', edgecolor='black', alpha=0.7)
ticks = np.arange(0, 5500, 500)
np.append(ticks, num_above_0)
plt.yticks(ticks)  # Add xtick at x=38
plt.axhline(num_above_0, color='purple', linestyle='--', label="Number of Estimates Above 0")
# plt.title("Histogram of Importance Sampling Estimates", fontsize=14)
plt.xlabel("Estimated Expected Utility Value", fontsize=22)
plt.ylabel("Frequency", fontsize=22)
true_expected_utility = np.mean(y * pdf)
standard_deviation = np.std(pdf*y)
plt.axvline(np.mean(y*pdf), color='red', linestyle='--', label='True Expected Utility', linewidth=1.5)
plt.axvline(0, color='green', label='Zero Utility')
# plt.axvline(true_expected_utility - 2 * standard_deviation, color='red', linestyle='--', label='-2 SD', linewidth=1.5, alpha=0.5)
# plt.axvline(true_expected_utility + 2 * standard_deviation, color='red', linestyle='--', label='+2 SD', linewidth=1.5, alpha=0.5)
plt.grid(True, linestyle='--', alpha=0.5)
plt.legend(fontsize=18)
plt.show()

#HISTOGRAMS for storming capitol
import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import beta

# Define a function to sample outcomes using RS
def RS_sample_outcome(px, fx):
    outcome_indices = np.arange(len(fx))
    sampled_outcome_index = np.random.choice(outcome_indices, p=px)
    sampled_outcome_value = fx[sampled_outcome_index]
    return sampled_outcome_index, sampled_outcome_value

# Parameters
p_beta_params = [1, 5]
nsamp = 100000

# Generate x values and calculate PDF
x = np.linspace(0.000001, 0.99999, nsamp)
pdf = beta.pdf(x, p_beta_params[0], p_beta_params[1])
pdf = pdf / np.sum(pdf)  # Normalize PDF

# Utility values (replace 'y' with your utility function)
nsamp = 100000
m = -110
b = 10
x = np.linspace(0.000001, 0.99999, nsamp)
y = m * x + b
# Sample outcomes using IS and RS methods
num_samples = 1000

# Representative Sampling (RS)
sampled_outcome_indices_RS = []
for _ in range(num_samples):
    RS_sampled_outcome_index, _ = RS_sample_outcome(pdf, y)
    sampled_outcome_indices_RS.append(RS_sampled_outcome_index / len(pdf))

# Importance Sampling (IS)
sampled_outcome_indices_IS = []
for _ in range(num_samples):
    IS_sampled_outcome_index, _, _ = IS_sample_outcome(pdf, y)
    sampled_outcome_indices_IS.append(IS_sampled_outcome_index / len(pdf))

# Plot histograms with improved styling
plt.figure(figsize=(10, 6))

# Representative Sampling (RS) histogram
plt.hist(sampled_outcome_indices_RS, bins=[0, 0.25, 0.5, 0.75, 1], color='blue', alpha=0.7, label='Representative Sampling')
plt.xlabel("Sampled Outcome (Percentage of Republicans)")
plt.ylabel("Frequency")
plt.title("Histogram of Sampled Outcomes with Representative Sampling")
plt.grid(True, linestyle='--', alpha=0.5)
plt.legend()

# Importance Sampling (IS) histogram
plt.figure(figsize=(10, 6))
plt.hist(sampled_outcome_indices_IS, bins=[0, 0.25, 0.5, 0.75, 1], color='red', alpha=0.7, label='Importance Sampling')
plt.xlabel("Sampled Outcome (Percentage of Republicans)")
plt.ylabel("Frequency")
plt.title("Histogram of Sampled Outcomes with Importance Sampling")
plt.grid(True, linestyle='--', alpha=0.5)
plt.legend()

plt.show()

#PLOTTING FHAT FOR IS AND RS TOGETHER

# Plotting f-hat k IS Sampling
import numpy as np
import matplotlib.pyplot as plt
import matplotlib as mpl

offset= 0.01


# Sample outcome using Importance Sampling. Returns index and value
def IS_sample_outcome(px, fx):
    outcome_indices = np.arange(len(fx))
    qx = generate_qx(px, fx)
    sampled_outcome_index = np.random.choice(outcome_indices, p=qx)
    sampled_outcome_value = fx[sampled_outcome_index]
    weight = px[sampled_outcome_index] / qx[sampled_outcome_index]
    return (sampled_outcome_index, sampled_outcome_value, weight)

def IS_sample_outcomes(px, fx, num_samples=50):
    outcome_indices = np.arange(len(fx))
    qx = generate_qx(px, fx)
    sampled_outcome_indices = np.random.choice(outcome_indices, p=qx, size=num_samples)
    sampled_outcome_values = fx[sampled_outcome_indices]
    return (sampled_outcome_indices, sampled_outcome_values)

# Generate the q distribution
def generate_qx(px, fx):
    # qx = px*np.abs((fx-np.mean(fx)))
    qx = px*np.abs(fx)
    qx = qx / np.sum(qx)
    return qx

# Parameters
num_simulations = 1000
num_samples_per_simulation = 1000

# Parameters
p_beta_params = [1, 5]
nsamp = 100000

# Generate x values and calculate PDF
x = np.linspace(0.000001, 0.99999, nsamp)
pdf = beta.pdf(x, p_beta_params[0], p_beta_params[1])
pdf = pdf / np.sum(pdf)  # Normalize PDF

# Example utility values (replace with your actual utility values)
nsamp = 100000
m = -110
b = 10
x = np.linspace(0.000001, 0.99999, nsamp)
y = m * x + b
# Define outcome bins based on percentage of Republicans believing they should storm the Capitol
bins = [(0, nsamp/4), (nsamp/4, nsamp/4*2), (nsamp/4*2, nsamp/4*3), (nsamp/4*3, nsamp)]

# Initialize list to store all predicted probabilities
predicted_probs_all = []

# Run multiple simulations
for _ in range(num_simulations):
    # Sample outcomes using RS_sample_outcome and calculate weights
    weights = []
    sampled_outcomes, sampled_utilities = IS_sample_outcomes(pdf, y, num_samples_per_simulation)  # Use RS_sample_outcome to get the outcome index
    weights = 1 / np.abs(sampled_utilities)  # Calculate weight based on sampled outcome

    # Convert lists to numpy arrays.
    sampled_outcomes = np.array(sampled_outcomes)
    weights = np.array(weights)
    # Calculate predicted probabilities for each bin in this simulation
    predicted_probs = []
    for bin_start, bin_end in bins:
        # Filter outcomes within the current bin range
        outcomes_in_bin = sampled_outcomes[(sampled_outcomes >= bin_start) & (sampled_outcomes < bin_end)]
        weights_in_bin = weights[(sampled_outcomes >= bin_start) & (sampled_outcomes < bin_end)]
        # Calculate predicted probability for the bin in this simulation
        if len(outcomes_in_bin) > 0:
            sum_weights_in_bin = np.sum(weights_in_bin)
            predicted_prob = sum_weights_in_bin / np.sum(weights)


        else:
            predicted_prob = 0.0
        predicted_probs.append(predicted_prob)
    # Append predicted probabilities from this simulation to the list
    predicted_probs_all.extend(predicted_probs)
# Prepare data for plotting
bin_centers = [0.125+offset, 0.375+offset, 0.625+offset, 0.875+offset]* num_simulations # Centers of the four bins repeated for each simulation
# predicted_probs_flat = np.array(predicted_probs_all)  # Flatten predicted probabilities list
# print(predicted_probs_flat)
# Plotting the predicted probabilities as "X" marks centered within each bin
plt.figure(figsize=(12, 8))
plt.plot(bin_centers, predicted_probs_all, 'bx', markersize=3, color="red", label="Importance Sampling")  # Plotting as "X" marks
plt.xlabel("Percentage of Republicans Believing They\nShould Storm the Capitol", fontsize=24)
plt.ylabel("Predicted Probability", fontsize=24)
# plt.title(f"Predicted Probabilities of Outcome Bins Using Importance Sampling (In {num_simulations} Simulations)",fontsize=20)
plt.xticks([0.125, 0.375, 0.625, 0.875], ['0-25%', '25-50%', '50-75%', '75-100%'], fontsize=16, rotation=45)
plt.grid(True, linestyle='--', alpha=0.5)
# plt.show()



# Parameters
p_beta_params = [1, 5]
nsamp = 100000
# Generate x values and calculate PDF
x = np.linspace(0.000001, 0.99999, nsamp)
pdf = beta.pdf(x, p_beta_params[0], p_beta_params[1])
pdf = pdf / np.sum(pdf)  # Normalize PDF

# Utility values (replace 'y' with your utility function)
nsamp = 100000
m = -110
b = 10
x = np.linspace(0.000001, 0.99999, nsamp)
y = m * x + b

# Define the RS_sample_outcome function (replace with your implementation)
def RS_sample_outcome(px, fx):
    outcome_indices = np.arange(len(fx))
    sampled_outcome_index = np.random.choice(outcome_indices, p=px)
    sampled_outcome_value = fx[sampled_outcome_index]
    return sampled_outcome_index, sampled_outcome_value

def RS_sample_outcomes(px, fx, num_samples=50):
    outcome_indices = np.arange(len(fx))
    sampled_outcome_indices = np.random.choice(outcome_indices, p=px, size=num_samples)
    sampled_outcome_values = fx[sampled_outcome_indices]
    return sampled_outcome_indices, sampled_outcome_values

# Parameters
num_simulations = 1000
num_samples_per_simulation = 1000

# Parameters
p_beta_params = [1, 5]
nsamp = 100000

# Generate x values and calculate PDF
x = np.linspace(0.000001, 0.99999, nsamp)
pdf = beta.pdf(x, p_beta_params[0], p_beta_params[1])
pdf = pdf / np.sum(pdf)  # Normalize PDF

# Example utility values (replace with your actual utility values)
nsamp = 100000
m = -110
b = 10
x = np.linspace(0.000001, 0.99999, nsamp)
y = m * x + b
# Define outcome bins based on percentage of Republicans believing they should storm the Capitol
bins = [(0, nsamp/4), (nsamp/4, nsamp/4*2), (nsamp/4*2, nsamp/4*3), (nsamp/4*3, nsamp)]

# Initialize list to store all predicted probabilities
predicted_probs_all = []

# Run multiple simulations
for _ in range(num_simulations):
    # Sample outcomes using RS_sample_outcome and calculate weights
    sampled_outcomes, sampled_utilities = RS_sample_outcomes(pdf, y, num_samples_per_simulation)  # Use RS_sample_outcome to get the outcome index
    weights = 1 / np.abs(sampled_utilities)  # Calculate weight based on sampled outcome

    # Convert lists to numpy arrays.
    sampled_outcomes = np.array(sampled_outcomes)
    weights = np.array(weights)
    # Calculate predicted probabilities for each bin in this simulation
    predicted_probs = []
    for bin_start, bin_end in bins:
        # Filter outcomes within the current bin range
        outcomes_in_bin = sampled_outcomes[(sampled_outcomes >= bin_start) & (sampled_outcomes < bin_end)]
        weights_in_bin = weights[(sampled_outcomes >= bin_start) & (sampled_outcomes < bin_end)]
        # Calculate predicted probability for the bin in this simulation
        if len(outcomes_in_bin) > 0:
            sum_weights_in_bin = np.sum(weights_in_bin)
            predicted_prob = sum_weights_in_bin / np.sum(weights)


        else:
            predicted_prob = 0.0
        predicted_probs.append(predicted_prob)
    # Append predicted probabilities from this simulation to the list
    predicted_probs_all.extend(predicted_probs)
# Prepare data for plotting
bin_centers = [0.125-offset, 0.375-offset, 0.625-offset, 0.875-offset]* num_simulations # Centers of the four bins repeated for each simulation
# predicted_probs_flat = np.array(predicted_probs_all)  # Flatten predicted probabilities list
# print(predicted_probs_flat)
# Plotting the predicted probabilities as "X" marks centered within each bin
plt.plot(bin_centers, predicted_probs_all, 'bx', markersize=3, color="blue", label="Representative Sampling")  # Plotting as "X" marks
plt.legend(fontsize=18)
plt.show()

# Plotting p(x), f(x), and q(x) for Police Are Bad
import numpy as np
from scipy.stats import norm
import matplotlib.pyplot as plt

axis_fontsize=18
nsamp = 100000

# Storming the Capitol p(x)
mu = 0.5  # Mean of the normal distribution
sigma = 0.2  # Standard deviation of the normal distribution
x = np.linspace(0.001, 0.999, nsamp)
pdf = norm.pdf(x, loc=mu, scale=sigma)

plt.figure(figsize=(10, 6))  # Set figure size
plt.plot(x, pdf, color='red', label='p(x)', linewidth=2)
# plt.title("Probability Distribution of Percentage of Republicans\nBelieving They Should Storm the Capitol", fontsize=18)
plt.xlabel("Percentage of Democrats Who Believe\nPolice Are Bad", fontsize=axis_fontsize)
plt.ylabel("Probabibility Density", fontsize=axis_fontsize)
plt.grid(True, linestyle='--', alpha=0.5)  # Add grid lines
plt.legend(fontsize=12)
plt.tight_layout()  # Adjust layout to prevent clipping
plt.show()



# Storming the Capitol f(x)
m = -100
b = 50
x = np.linspace(0, 1, nsamp)  # Generate 100000 points from 0 to 1
y = m * x + b
plt.figure(figsize=(10, 6))  # Set figure size
plt.plot(x, y, color='blue', label='Utility Function: $y = -100x + 50$', linewidth=2)
# plt.title("Utility Function for Republicans Believe Police Are Bad", fontsize=18)
plt.xlabel("Percentage of Democrats Who Believe Police Are Bad", fontsize=axis_fontsize)
plt.ylabel("Utility (Negative or Positive Impact)", fontsize=axis_fontsize)
plt.yticks(np.arange(-50, 60, 10))
plt.axhline(0, color='red', linestyle='--', label='Zero Utility', linewidth=1.5)
plt.grid(True, linestyle='--', alpha=0.5)  # Add grid lines
plt.legend(fontsize=12)
plt.tight_layout()  # Adjust layout to prevent clipping
plt.show()

# Storming the Capitol q(x)
qx = pdf * np.abs(y)

plt.figure(figsize=(10, 6))  # Set figure size
plt.plot(x, qx, color='orange', label='q(x)', linewidth=2)
# plt.title("Distribution of q(x) for Republicans Believing Police Are Bad", fontsize=18)
plt.xlabel("Percentage of Democrats Who Believe Police Are Bad", fontsize=axis_fontsize)
plt.ylabel("Importance-Weighted Probability Density", fontsize=axis_fontsize)
plt.grid(True, linestyle='--', alpha=0.5)  # Add grid lines
plt.axhline(0, color='black', linewidth=0.5)  # Horizontal line at y=0
plt.axvline(0, color='black', linewidth=0.5)  # Vertical line at x=0
plt.legend(fontsize=12)
plt.tight_layout()  # Adjust layout to prevent clipping
plt.show()

#PLOTTING FHAT FOR IS AND RS TOGETHER

# Plotting f-hat k IS Sampling
import numpy as np
import matplotlib.pyplot as plt
import matplotlib as mpl
from scipy.stats import norm

offset= 0.01


# Sample outcome using Importance Sampling. Returns index and value
def IS_sample_outcome(px, fx):
    outcome_indices = np.arange(len(fx))
    qx = generate_qx(px, fx)
    sampled_outcome_index = np.random.choice(outcome_indices, p=qx)
    sampled_outcome_value = fx[sampled_outcome_index]
    weight = px[sampled_outcome_index] / qx[sampled_outcome_index]
    return (sampled_outcome_index, sampled_outcome_value, weight)

def IS_sample_outcomes(px, fx, num_samples=50):
    outcome_indices = np.arange(len(fx))
    qx = generate_qx(px, fx)
    sampled_outcome_indices = np.random.choice(outcome_indices, p=qx, size=num_samples)
    sampled_outcome_values = fx[sampled_outcome_indices]
    return (sampled_outcome_indices, sampled_outcome_values)

# Generate the q distribution
def generate_qx(px, fx):
    # qx = px*np.abs((fx-np.mean(fx)))
    qx = px*np.abs(fx)
    qx = qx / np.sum(qx)
    return qx

# Parameters
num_simulations = 1000
num_samples_per_simulation = 10

# Parameters
nsamp = 100000

# Storming the Capitol p(x)
mu = 0.5  # Mean of the normal distribution
sigma = 0.2  # Standard deviation of the normal distribution
x = np.linspace(0.001, 0.999, nsamp)
pdf = norm.pdf(x, loc=mu, scale=sigma)
pdf = pdf / np.sum(pdf)


# Example utility values (replace with your actual utility values)
nsamp = 100000
m = -100
b = 50
x = np.linspace(0, 1, nsamp)  # Generate 100000 points from 0 to 1
y = m * x + b
# Define outcome bins based on percentage of Republicans believing they should storm the Capitol
bins = [(0, nsamp/4), (nsamp/4, nsamp/4*2), (nsamp/4*2, nsamp/4*3), (nsamp/4*3, nsamp)]

# Initialize list to store all predicted probabilities
predicted_probs_all = []

# Run multiple simulations
for _ in range(num_simulations):
    # Sample outcomes using RS_sample_outcome and calculate weights
    weights = []
    sampled_outcomes, sampled_utilities = IS_sample_outcomes(pdf, y, num_samples_per_simulation)  # Use RS_sample_outcome to get the outcome index
    weights = 1 / np.abs(sampled_utilities)  # Calculate weight based on sampled outcome

    # Convert lists to numpy arrays.
    sampled_outcomes = np.array(sampled_outcomes)
    weights = np.array(weights)
    # Calculate predicted probabilities for each bin in this simulation
    predicted_probs = []
    for bin_start, bin_end in bins:
        # Filter outcomes within the current bin range
        outcomes_in_bin = sampled_outcomes[(sampled_outcomes >= bin_start) & (sampled_outcomes < bin_end)]
        weights_in_bin = weights[(sampled_outcomes >= bin_start) & (sampled_outcomes < bin_end)]
        # Calculate predicted probability for the bin in this simulation
        if len(outcomes_in_bin) > 0:
            sum_weights_in_bin = np.sum(weights_in_bin)
            predicted_prob = sum_weights_in_bin / np.sum(weights)


        else:
            predicted_prob = 0.0
        predicted_probs.append(predicted_prob)
    # Append predicted probabilities from this simulation to the list
    predicted_probs_all.extend(predicted_probs)
# Prepare data for plotting
bin_centers = [0.125+offset, 0.375+offset, 0.625+offset, 0.875+offset]* num_simulations # Centers of the four bins repeated for each simulation
# predicted_probs_flat = np.array(predicted_probs_all)  # Flatten predicted probabilities list
# print(predicted_probs_flat)
# Plotting the predicted probabilities as "X" marks centered within each bin
plt.figure(figsize=(12, 8))
plt.plot(bin_centers, predicted_probs_all, 'bx', markersize=3, color="red", label="Importance Sampling 10 samples")  # Plotting as "X" marks
plt.xlabel("Percentage of Democrats Believing Police Are Bad", fontsize=22)
plt.ylabel("Predicted Probability", fontsize=22)
# plt.title(f"Predicted Probabilities of Outcome Bins Using Importance Sampling (In {num_simulations} Simulations)",fontsize=20)
plt.xticks([0.125, 0.375, 0.625, 0.875], ['0-25%', '25-50%', '50-75%', '75-100%'], fontsize=16, rotation=45)
plt.grid(True, linestyle='--', alpha=0.5)
print(predicted_probs_all)
predicted_probs_all = np.array(predicted_probs_all)
print("10 samples Average: ", np.mean(predicted_probs_all[predicted_probs_all > 0.5]))

# plt.show()

# ONE HUNDRED SAMLES!!

# Parameters
num_simulations = 1000
num_samples_per_simulation = 100

# Initialize list to store all predicted probabilities
predicted_probs_all = []

# Run multiple simulations
for _ in range(num_simulations):
    # Sample outcomes using RS_sample_outcome and calculate weights
    weights = []
    sampled_outcomes, sampled_utilities = IS_sample_outcomes(pdf, y, num_samples_per_simulation)  # Use RS_sample_outcome to get the outcome index
    weights = 1 / np.abs(sampled_utilities)  # Calculate weight based on sampled outcome

    # Convert lists to numpy arrays.
    sampled_outcomes = np.array(sampled_outcomes)
    weights = np.array(weights)
    # Calculate predicted probabilities for each bin in this simulation
    predicted_probs = []
    for bin_start, bin_end in bins:
        # Filter outcomes within the current bin range
        outcomes_in_bin = sampled_outcomes[(sampled_outcomes >= bin_start) & (sampled_outcomes < bin_end)]
        weights_in_bin = weights[(sampled_outcomes >= bin_start) & (sampled_outcomes < bin_end)]
        # Calculate predicted probability for the bin in this simulation
        if len(outcomes_in_bin) > 0:
            sum_weights_in_bin = np.sum(weights_in_bin)
            predicted_prob = sum_weights_in_bin / np.sum(weights)


        else:
            predicted_prob = 0.0
        predicted_probs.append(predicted_prob)
    # Append predicted probabilities from this simulation to the list
    predicted_probs_all.extend(predicted_probs)
# Prepare data for plotting
bin_centers = [0.125+2*offset, 0.375+2*offset, 0.625+2*offset, 0.875+2*offset]* num_simulations # Centers of the four bins repeated for each simulation
# predicted_probs_flat = np.array(predicted_probs_all)  # Flatten predicted probabilities list
# print(predicted_probs_flat)
# Plotting the predicted probabilities as "X" marks centered within each bin
plt.plot(bin_centers, predicted_probs_all, 'bx', markersize=3, color="blue", label="Importance Sampling 100 samples")  # Plotting as "X" marks
predicted_probs_all = np.array(predicted_probs_all)
print("100 samples Average: ", np.mean(predicted_probs_all[predicted_probs_all > 0.5]))

# 1000 SAMLES

num_simulations = 1000
num_samples_per_simulation = 1000

# Initialize list to store all predicted probabilities
predicted_probs_all = []

# Run multiple simulations
for _ in range(num_simulations):
    # Sample outcomes using RS_sample_outcome and calculate weights
    weights = []
    sampled_outcomes, sampled_utilities = IS_sample_outcomes(pdf, y, num_samples_per_simulation)  # Use RS_sample_outcome to get the outcome index
    weights = 1 / np.abs(sampled_utilities)  # Calculate weight based on sampled outcome

    # Convert lists to numpy arrays.
    sampled_outcomes = np.array(sampled_outcomes)
    weights = np.array(weights)
    # Calculate predicted probabilities for each bin in this simulation
    predicted_probs = []
    for bin_start, bin_end in bins:
        # Filter outcomes within the current bin range
        outcomes_in_bin = sampled_outcomes[(sampled_outcomes >= bin_start) & (sampled_outcomes < bin_end)]
        weights_in_bin = weights[(sampled_outcomes >= bin_start) & (sampled_outcomes < bin_end)]
        # Calculate predicted probability for the bin in this simulation
        if len(outcomes_in_bin) > 0:
            sum_weights_in_bin = np.sum(weights_in_bin)
            predicted_prob = sum_weights_in_bin / np.sum(weights)


        else:
            predicted_prob = 0.0
        predicted_probs.append(predicted_prob)
    # Append predicted probabilities from this simulation to the list
    predicted_probs_all.extend(predicted_probs)
# Prepare data for plotting
bin_centers = [0.125+3*offset, 0.375+3*offset, 0.625+3*offset, 0.875+3*offset]* num_simulations # Centers of the four bins repeated for each simulation
# predicted_probs_flat = np.array(predicted_probs_all)  # Flatten predicted probabilities list
# print(predicted_probs_flat)
# Plotting the predicted probabilities as "X" marks centered within each bin
plt.plot(bin_centers, predicted_probs_all, 'bx', markersize=3, color="green", label="Importance Sampling 1000 samples")  # Plotting as "X" marks
plt.legend(fontsize=18)
predicted_probs_all = np.array(predicted_probs_all)
print("1000 samples Average: ", np.mean(predicted_probs_all[predicted_probs_all > 0.5]))

# plt.show()


# Parameters
nsamp = 100000
mu = 0.5  # Mean of the normal distribution
sigma = 0.2  # Standard deviation of the normal distribution
x = np.linspace(0.001, 0.999, nsamp)
pdf = norm.pdf(x, loc=mu, scale=sigma)

# Utility values (replace 'y' with your utility function)
nsamp = 100000
m = -100
b = 50
x = np.linspace(0, 1, nsamp)  # Generate 100000 points from 0 to 1
y = m * x + b

# Define the RS_sample_outcome function (replace with your implementation)
def RS_sample_outcome(px, fx):
    outcome_indices = np.arange(len(fx))
    sampled_outcome_index = np.random.choice(outcome_indices, p=px)
    sampled_outcome_value = fx[sampled_outcome_index]
    return sampled_outcome_index, sampled_outcome_value

def RS_sample_outcomes(px, fx, num_samples=50):
    outcome_indices = np.arange(len(fx))
    sampled_outcome_indices = np.random.choice(outcome_indices, p=px, size=num_samples)
    sampled_outcome_values = fx[sampled_outcome_indices]
    return sampled_outcome_indices, sampled_outcome_values

# Parameters
num_simulations = 1000
num_samples_per_simulation = 1000

# Parameters
mu = 0.5  # Mean of the normal distribution
sigma = 0.2  # Standard deviation of the normal distribution
x = np.linspace(0.001, 0.999, nsamp)
pdf = norm.pdf(x, loc=mu, scale=sigma)
pdf = pdf / np.sum(pdf)

# Example utility values (replace with your actual utility values)
nsamp = 100000
m = -100
b = 50
x = np.linspace(0.000001, 0.99999, nsamp)
y = m * x + b
# Define outcome bins based on percentage of Republicans believing they should storm the Capitol
bins = [(0, nsamp/4), (nsamp/4, nsamp/4*2), (nsamp/4*2, nsamp/4*3), (nsamp/4*3, nsamp)]

# Initialize list to store all predicted probabilities
predicted_probs_all = []

# Run multiple simulations
for _ in range(num_simulations):
    # Sample outcomes using RS_sample_outcome and calculate weights
    sampled_outcomes, sampled_utilities = RS_sample_outcomes(pdf, y, num_samples_per_simulation)  # Use RS_sample_outcome to get the outcome index
    weights = 1 / np.abs(sampled_utilities)  # Calculate weight based on sampled outcome

    # Convert lists to numpy arrays.
    sampled_outcomes = np.array(sampled_outcomes)
    weights = np.array(weights)
    # Calculate predicted probabilities for each bin in this simulation
    predicted_probs = []
    for bin_start, bin_end in bins:
        # Filter outcomes within the current bin range
        outcomes_in_bin = sampled_outcomes[(sampled_outcomes >= bin_start) & (sampled_outcomes < bin_end)]
        weights_in_bin = weights[(sampled_outcomes >= bin_start) & (sampled_outcomes < bin_end)]
        # Calculate predicted probability for the bin in this simulation
        if len(outcomes_in_bin) > 0:
            sum_weights_in_bin = np.sum(weights_in_bin)
            predicted_prob = sum_weights_in_bin / np.sum(weights)


        else:
            predicted_prob = 0.0
        predicted_probs.append(predicted_prob)
    # Append predicted probabilities from this simulation to the list
    predicted_probs_all.extend(predicted_probs)
# Prepare data for plotting
bin_centers = [0.125-offset, 0.375-offset, 0.625-offset, 0.875-offset]* num_simulations # Centers of the four bins repeated for each simulation
# predicted_probs_flat = np.array(predicted_probs_all)  # Flatten predicted probabilities list
# print(predicted_probs_flat)
# Plotting the predicted probabilities as "X" marks centered within each bin
plt.plot(bin_centers, predicted_probs_all, 'bx', markersize=3, color="orange", label="Representative Sampling")  # Plotting as "X" marks
# plt.legend(fontsize=18)
predicted_probs_all = np.array(predicted_probs_all)
print(np.mean(predicted_probs_all[predicted_probs_all > 0.5]))
plt.show()

